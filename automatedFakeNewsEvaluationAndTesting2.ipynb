{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Combine Dataset Parts"
      ],
      "metadata": {
        "id": "qAZ7Z21a0QG9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Buhfi9dk5eXG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url_1 = \"\"\n",
        "url_2 = \"\"\n",
        "url_3 = \"\"\n",
        "url_4 = \"\"\n",
        "url_5 = \"\"\n",
        "url_6 = \"\"\n",
        "url_7 = \"\"\n",
        "url_8 = \"\"\n",
        "url_9 = \"\"\n",
        "url_10 = \"\"\n",
        "\n",
        "df_1 = pd.read_csv(url_1)\n",
        "df_2 = pd.read_csv(url_2)\n",
        "df_3 = pd.read_csv(url_3)\n",
        "df_4 = pd.read_csv(url_4)\n",
        "df_5 = pd.read_csv(url_5)\n",
        "df_6 = pd.read_csv(url_6)\n",
        "df_7 = pd.read_csv(url_7)\n",
        "df_8 = pd.read_csv(url_8)\n",
        "df_9 = pd.read_csv(url_9)\n",
        "df_10 = pd.read_csv(url_10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combinedTestDataFrameWithPrediction = pd.concat([df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8, df_9, df_10], ignore_index=True)"
      ],
      "metadata": {
        "id": "TPFMlBZ6qlqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HrmsqPge5JY"
      },
      "outputs": [],
      "source": [
        "combinedTestDataFrameWithPrediction.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Gh5qetz2CR"
      },
      "source": [
        "## Save Combined Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hafr6Ci5WEk"
      },
      "outputs": [],
      "source": [
        "fileName = f\"completeAutomatatedFakeNewsTestWithPrediction.csv\"\n",
        "combinedTestDataFrameWithPrediction.to_csv(fileName, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "blpxNvkC00gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def findMetrics(actualLabel, predictionLabel):\n",
        "\n",
        "  targetNames = [\"real (0)\", \"fake (1)\"]\n",
        "  metricsAsDictionary = classification_report(actualLabel, predictionLabel, target_names = targetNames, output_dict=True)\n",
        "  metricsAsString = classification_report(actualLabel, predictionLabel, target_names = targetNames)\n",
        "\n",
        "  metrics = [metricsAsDictionary, metricsAsString]\n",
        "\n",
        "  return metrics\n",
        "\n",
        "\n",
        "def findConfusionMatrix(actualLabel, predictionLabel):\n",
        "  confusionMatrix = confusion_matrix(actualLabel, predictionLabel)\n",
        "  return confusionMatrix\n",
        "\n"
      ],
      "metadata": {
        "id": "XIIh3NLJ1neV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actualLabel = combinedTestDataFrameWithPrediction['label']\n",
        "predictionLabel = combinedTestDataFrameWithPrediction['prediction']"
      ],
      "metadata": {
        "id": "StYa8jAa5Q_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = findMetrics(actualLabel, predictionLabel)\n",
        "confusionMatrix = findConfusionMatrix(actualLabel, predictionLabel)"
      ],
      "metadata": {
        "id": "t-WW9gTlsKEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Findings"
      ],
      "metadata": {
        "id": "ofd8rHhu0-Xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def showMetrics(metricsAsString):\n",
        "  print(\"Automated Fake News Detector Performance Metrics \\n\")\n",
        "  print(metricsAsString)\n",
        "\n",
        "def showConfusionMatrix(confusionMatrix, modelName):\n",
        "  display = ConfusionMatrixDisplay(confusion_matrix=confusionMatrix, display_labels=[\"Real News\", \"Fake News\"])\n",
        "  display.plot(include_values=True, cmap='viridis', ax=None, xticks_rotation='horizontal')\n",
        "  plt.title(modelName + \" Confusion Matrix\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Cin9ry8i09vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showMetrics(metrics[1])\n",
        "showConfusionMatrix(confusionMatrix, \"Automated Fake News Detector\")"
      ],
      "metadata": {
        "id": "0uRFgKXoc-k4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSd5+peU+/Bf20SgJ8LK1U"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}